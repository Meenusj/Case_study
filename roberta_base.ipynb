{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWQjB3e7IUtxT5rAlE19O/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meenusj/Case_study/blob/main/roberta_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6_F7v95KKK6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caVJ7BnS2t2P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALCfORJBMHqA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n"
      ],
      "metadata": {
        "id": "dFWB0tl_hJFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYalq22mgk7K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import torch\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/combined_mutation_results (1).csv\"  # Replace with the actual path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the text data\n",
        "def preprocess_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "mutation_columns = ['char_mutated_article', 'char_mutated_adjective', 'char_mutated_adverb',\n",
        "                    'word_mutated_articles', 'word_mutated_adjectives', 'word_mutated_adverbs']\n",
        "\n",
        "for col in mutation_columns:\n",
        "    df[col] = df[col].apply(preprocess_text)\n",
        "\n",
        "# Concatenate mutation columns into one\n",
        "df['mutations_combined'] = df[mutation_columns].apply(lambda x: ' '.join(x), axis=1)\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Shuffle the datasets\n",
        "train_df = shuffle(train_df, random_state=42).reset_index(drop=True)\n",
        "val_df = shuffle(val_df, random_state=42).reset_index(drop=True)\n",
        "test_df = shuffle(test_df, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Define file paths for saving the datasets\n",
        "train_file = \"train.csv\"\n",
        "val_file = \"validation.csv\"\n",
        "test_file = \"test.csv\"\n",
        "\n",
        "# Save the datasets to CSV files\n",
        "train_df.to_csv(train_file, index=False)\n",
        "val_df.to_csv(val_file, index=False)\n",
        "test_df.to_csv(test_file, index=False)\n",
        "\n",
        "# Load RoBERTa tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Tokenize the text data\n",
        "train_encodings = tokenizer(train_df['mutations_combined'].tolist(), truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(val_df['mutations_combined'].tolist(), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Convert labels to numerical format\n",
        "label_mapping = {'human': 0, 'bot': 1, 'rnn': 1, 'gpt2': 1, 'others': 1}\n",
        "train_labels = train_df['class_type'].map(label_mapping).tolist()\n",
        "val_labels = val_df['class_type'].map(label_mapping).tolist()\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class DetectionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DetectionDataset(train_encodings, train_labels)\n",
        "val_dataset = DetectionDataset(val_encodings, val_labels)\n",
        "\n",
        "# Load pre-trained RoBERTa-Base model\n",
        "roberta_base_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Define the training arguments with reduced batch size\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./roberta_base_model\",\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=32,  # Reduce the batch size here\n",
        "    per_device_eval_batch_size=32,    # Reduce the batch size here\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    learning_rate=1e-4,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Define the Trainer with the updated training arguments\n",
        "trainer = Trainer(\n",
        "    model=roberta_base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=lambda pred: {\"accuracy\": accuracy_score(pred.label_ids, pred.predictions.argmax(-1))},\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_df=pd.read_csv(\"/content/test.csv\")"
      ],
      "metadata": {
        "id": "c-Ji2C--F8kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tabulate import tabulate\n",
        "\n",
        "def evaluate_mutation(trainer, tokenizer, test_df, mutation_column, label_mapping):\n",
        "    # Tokenize the test data for the specified mutation\n",
        "    test_encodings = tokenizer(test_df[mutation_column].tolist(), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # Create PyTorch dataset for the specified mutation\n",
        "    test_labels = test_df['class_type'].map(label_mapping).tolist()\n",
        "    test_dataset = DetectionDataset(test_encodings, test_labels)\n",
        "\n",
        "    # Evaluate on the specified mutation test set\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "\n",
        "    # Get predicted labels and probabilities\n",
        "    predicted_labels = predictions.predictions.argmax(-1)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=-1)\n",
        "\n",
        "    # Calculate accuracy and AUC for the specified mutation\n",
        "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "    auc = roc_auc_score(test_labels, probs[:, 1])\n",
        "\n",
        "    return accuracy, auc\n",
        "\n",
        "# Evaluate each mutation separately including original text\n",
        "mutations = ['original_text', 'char_mutated_article', 'char_mutated_adjective', 'char_mutated_adverb',\n",
        "             'word_mutated_articles', 'word_mutated_adjectives', 'word_mutated_adverbs']\n",
        "\n",
        "results = []\n",
        "for mutation in mutations:\n",
        "    mutation_accuracy, mutation_auc = evaluate_mutation(trainer, tokenizer, test_df, mutation, label_mapping)\n",
        "    if mutation == 'original_text':\n",
        "        mutation = 'Human'\n",
        "    results.append([mutation.capitalize(), mutation_accuracy, mutation_auc])\n",
        "\n",
        "print(\"Roberta Base\")\n",
        "print(tabulate(results, headers=[\"Mutation\", \"Accuracy\", \"AUC\"], tablefmt=\"fancy_grid\"))\n"
      ],
      "metadata": {
        "id": "MzuEnJRwOPcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"./roberta_base_model\"  # Path to the folder you want to move\n",
        "destination_path = \"/content/drive/MyDrive/roberta_base_model\"  # Path in your Google Drive\n",
        "\n",
        "# Move the folder to your Google Drive\n",
        "!cp -r $source_path $destination_path\n"
      ],
      "metadata": {
        "id": "pdF0SmnBg-pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_mutation(trainer, tokenizer, test_df, mutation_column, label_mapping):\n",
        "    # Tokenize the test data for the specified mutation\n",
        "    test_encodings = tokenizer(test_df[mutation_column].tolist(), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # Create PyTorch dataset for the specified mutation\n",
        "    test_labels = test_df['class_type'].map(label_mapping).tolist()\n",
        "    test_dataset = DetectionDataset(test_encodings, test_labels)\n",
        "\n",
        "    # Evaluate on the specified mutation test set\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "\n",
        "    # Get predicted labels and probabilities\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=-1)\n",
        "\n",
        "    # Calculate AUC for the specified mutation\n",
        "    auc = roc_auc_score(test_labels, probs[:, 1])\n",
        "\n",
        "    return auc\n",
        "\n",
        "# Evaluate each mutation separately including original text\n",
        "mutations = ['original_text', 'char_mutated_article', 'char_mutated_adjective', 'char_mutated_adverb',\n",
        "             'word_mutated_articles', 'word_mutated_adjectives', 'word_mutated_adverbs']\n",
        "\n",
        "auc_scores = []\n",
        "mutation_labels = []\n",
        "for mutation in mutations:\n",
        "    mutation_auc = evaluate_mutation(trainer, tokenizer, test_df, mutation, label_mapping)\n",
        "    auc_scores.append(mutation_auc)\n",
        "    if mutation == 'original_text':\n",
        "        mutation_labels.append('Original Text')\n",
        "    else:\n",
        "        mutation_labels.append(mutation.capitalize())\n",
        "\n",
        "# Define colors for each mutation\n",
        "colors = ['skyblue', 'salmon', 'lightgreen', 'lightcoral', 'orchid', 'gold', 'cyan']\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))  # Adjust the figure size as needed\n",
        "plt.bar(np.arange(len(mutations)), auc_scores, color=colors)\n",
        "plt.xlabel('Mutation')\n",
        "plt.ylabel('AUC')\n",
        "plt.title('Area Under the Curve (AUC) for Various Mutations')\n",
        "plt.xticks(np.arange(len(mutations)), mutation_labels, rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OKLrAL5_LWOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_mutation(trainer, tokenizer, test_df, mutation_column, label_mapping):\n",
        "    # Tokenize the test data for the specified mutation\n",
        "    test_encodings = tokenizer(test_df[mutation_column].tolist(), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # Create PyTorch dataset for the specified mutation\n",
        "    test_labels = test_df['class_type'].map(label_mapping).tolist()\n",
        "    test_dataset = DetectionDataset(test_encodings, test_labels)\n",
        "\n",
        "    # Evaluate on the specified mutation test set\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "\n",
        "    # Get predicted labels and probabilities\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=-1)\n",
        "\n",
        "    # Calculate ROC curve for the specified mutation\n",
        "    fpr, tpr, _ = roc_curve(test_labels, probs[:, 1])\n",
        "\n",
        "    return fpr, tpr\n",
        "\n",
        "# Evaluate each mutation separately including original text\n",
        "mutations = ['original_text', 'char_mutated_article', 'char_mutated_adjective', 'char_mutated_adverb',\n",
        "             'word_mutated_articles', 'word_mutated_adjectives', 'word_mutated_adverbs']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for mutation in mutations:\n",
        "    fpr, tpr = evaluate_mutation(trainer, tokenizer, test_df, mutation, label_mapping)\n",
        "    if mutation == 'original_text':\n",
        "        mutation_label = 'Original Text'\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        mutation_label = mutation.split('_')[1].capitalize()\n",
        "        color = 'C' + str(mutations.index(mutation))  # Use a unique color index for each mutation\n",
        "    plt.plot(fpr, tpr, label=mutation_label, color=color)\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Various Mutations')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0IsMVw9vYwwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bQgJ9UNWac9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}