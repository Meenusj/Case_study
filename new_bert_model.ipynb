{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHmEeQoOyc8ehkPlHSyiqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00a2aee386b546c29f10f21ddb9fb114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a05a314b768a4bf19034c8cbecc7bbb2",
              "IPY_MODEL_6cfbbcdedfc84237af1ead8e060106b8",
              "IPY_MODEL_41be356ccb32476ba305bfb4caa762c9"
            ],
            "layout": "IPY_MODEL_d6bed21175af4548939192a8bf57ef69"
          }
        },
        "a05a314b768a4bf19034c8cbecc7bbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c781724fa02744e4aaf0540fb611b2e4",
            "placeholder": "​",
            "style": "IPY_MODEL_17dfde63043943018222a088616ddfb1",
            "value": "model.safetensors: 100%"
          }
        },
        "6cfbbcdedfc84237af1ead8e060106b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a30cb4d7d84c4cabbd4527ef72ec7b",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d916175e47478c849b56a5b3028661",
            "value": 440449768
          }
        },
        "41be356ccb32476ba305bfb4caa762c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42dc75824b524ab0991fb64f4b28a8eb",
            "placeholder": "​",
            "style": "IPY_MODEL_ae398535a42145e4bd205845841acb93",
            "value": " 440M/440M [00:02&lt;00:00, 227MB/s]"
          }
        },
        "d6bed21175af4548939192a8bf57ef69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c781724fa02744e4aaf0540fb611b2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17dfde63043943018222a088616ddfb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8a30cb4d7d84c4cabbd4527ef72ec7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d916175e47478c849b56a5b3028661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42dc75824b524ab0991fb64f4b28a8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae398535a42145e4bd205845841acb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meenusj/Case_study/blob/main/new_bert_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP2LvCP7_KPD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "dataset1 = pd.read_csv('/content/LLM_generated_essay_PaLM.csv')\n",
        "\n",
        "# Print the first few rows and info of the dataset\n",
        "print(dataset1.head())\n",
        "print(dataset1.info())\n",
        "\n",
        "# Remove null values\n",
        "dataset1_cleaned = dataset1.dropna()\n",
        "\n",
        "# Keep only the 'text' and 'generated' columns\n",
        "dataset1_cleaned = dataset1_cleaned[['text', 'generated']]\n",
        "\n",
        "# Rename 'generated' to 'labels'\n",
        "dataset1_cleaned.rename(columns={'generated': 'labels'}, inplace=True)\n",
        "\n",
        "# Convert 'labels' to integers\n",
        "dataset1_cleaned['labels'] = dataset1_cleaned['labels'].astype(int)\n",
        "\n",
        "# Verify the changes\n",
        "print(dataset1_cleaned.head())\n",
        "print(dataset1_cleaned.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYWD5qww4oeX",
        "outputId": "cf438e6b-ab05-4c17-8fd4-0784491da757"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  prompt_id                                               text  generated\n",
            "0   0        0.0  ## The Advantages of Limiting Car Usage\\n\\nIn ...        1.0\n",
            "1   1        0.0  The United States is a car-dependent nation, w...        1.0\n",
            "2   2        0.0  In recent years, there has been a growing move...        1.0\n",
            "3   3        0.0  In recent years, there has been a growing move...        1.0\n",
            "4   4        0.0  In the past few decades, the United States has...        1.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1384 entries, 0 to 1383\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   id         1384 non-null   int64  \n",
            " 1   prompt_id  1384 non-null   float64\n",
            " 2   text       1384 non-null   object \n",
            " 3   generated  1384 non-null   float64\n",
            "dtypes: float64(2), int64(1), object(1)\n",
            "memory usage: 43.4+ KB\n",
            "None\n",
            "                                                text  labels\n",
            "0  ## The Advantages of Limiting Car Usage\\n\\nIn ...       1\n",
            "1  The United States is a car-dependent nation, w...       1\n",
            "2  In recent years, there has been a growing move...       1\n",
            "3  In recent years, there has been a growing move...       1\n",
            "4  In the past few decades, the United States has...       1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1384 entries, 0 to 1383\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1384 non-null   object\n",
            " 1   labels  1384 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 21.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "dataset2 = pd.read_csv('/content/reddit_filtered_dataset.csv')\n",
        "\n",
        "# Print the first few rows and info of the dataset\n",
        "print(dataset2.head())\n",
        "print(dataset2.info())\n",
        "\n",
        "# Remove null values\n",
        "dataset2_cleaned = dataset2.dropna()\n",
        "\n",
        "# Keep only the 'Data' and 'Labels' columns\n",
        "dataset2_cleaned = dataset2_cleaned[['Data', 'Labels']]\n",
        "\n",
        "# Rename 'Data' to 'text' and 'Labels' to 'labels'\n",
        "dataset2_cleaned.rename(columns={'Data': 'text', 'Labels': 'labels'}, inplace=True)\n",
        "\n",
        "# Ensure 'labels' is in integer format (this step might be redundant, but ensures consistency)\n",
        "dataset2_cleaned['labels'] = dataset2_cleaned['labels'].astype(int)\n",
        "\n",
        "# Verify the changes\n",
        "print(dataset2_cleaned.head())\n",
        "print(dataset2_cleaned.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDIx2_Xk5ddm",
        "outputId": "73940e65-fdb1-494e-a346-f3d542561f30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Data  Labels\n",
            "0  Of course! The relevant passage is: \"As to you...       0\n",
            "1  I've actually written a bit about this before....       0\n",
            "2  The Waco standoff in 1993 was a complex and co...       1\n",
            "3  Incredible answer. This was very well sourced ...       0\n",
            "4  The identification of the ruins of Troy is bas...       1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6513 entries, 0 to 6512\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Data    6513 non-null   object\n",
            " 1   Labels  6513 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 101.9+ KB\n",
            "None\n",
            "                                                text  labels\n",
            "0  Of course! The relevant passage is: \"As to you...       0\n",
            "1  I've actually written a bit about this before....       0\n",
            "2  The Waco standoff in 1993 was a complex and co...       1\n",
            "3  Incredible answer. This was very well sourced ...       0\n",
            "4  The identification of the ruins of Troy is bas...       1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6513 entries, 0 to 6512\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    6513 non-null   object\n",
            " 1   labels  6513 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 101.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaHddeXY4FkP",
        "outputId": "53fa996f-65ab-4311-87bf-47316d7779aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id  prompt_id                                               text  \\\n",
            "0  0059830c          0  Cars. Cars have been around since they became ...   \n",
            "1  005db917          0  Transportation is a large necessity in most co...   \n",
            "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
            "3  00940276          0  How often do you ride in a car? Do you drive a...   \n",
            "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
            "\n",
            "   generated  \n",
            "0          0  \n",
            "1          0  \n",
            "2          0  \n",
            "3          0  \n",
            "4          0  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1378 entries, 0 to 1377\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         1378 non-null   object\n",
            " 1   prompt_id  1378 non-null   int64 \n",
            " 2   text       1378 non-null   object\n",
            " 3   generated  1378 non-null   int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 43.2+ KB\n",
            "None\n",
            "                                                text  labels\n",
            "0  Cars. Cars have been around since they became ...       0\n",
            "1  Transportation is a large necessity in most co...       0\n",
            "2  \"America's love affair with it's vehicles seem...       0\n",
            "3  How often do you ride in a car? Do you drive a...       0\n",
            "4  Cars are a wonderful thing. They are perhaps o...       0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1378 entries, 0 to 1377\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1378 non-null   object\n",
            " 1   labels  1378 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 21.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "dataset3 = pd.read_csv('/content/train_essays.csv')\n",
        "\n",
        "# Print the first few rows and info of the dataset\n",
        "print(dataset3.head())\n",
        "print(dataset3.info())\n",
        "\n",
        "# Remove null values\n",
        "dataset3_cleaned = dataset3.dropna()\n",
        "\n",
        "# Keep only the 'text' and 'generated' columns\n",
        "dataset3_cleaned = dataset3_cleaned[['text', 'generated']]\n",
        "\n",
        "# Rename 'generated' to 'labels'\n",
        "dataset3_cleaned.rename(columns={'generated': 'labels'}, inplace=True)\n",
        "\n",
        "# Ensure 'labels' is in integer format\n",
        "dataset3_cleaned['labels'] = dataset3_cleaned['labels'].astype(int)\n",
        "\n",
        "# Verify the changes\n",
        "print(dataset3_cleaned.head())\n",
        "print(dataset3_cleaned.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the cleaned datasets\n",
        "combined_dataset = pd.concat([dataset1_cleaned, dataset2_cleaned, dataset3_cleaned])\n",
        "\n",
        "# Reset index after concatenation\n",
        "combined_dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Verify the combined dataset\n",
        "print(combined_dataset.info())\n",
        "print(combined_dataset.head())\n",
        "\n",
        "# Save the combined dataset\n",
        "combined_dataset.to_csv('/content/combined_cleaned_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TbK1W1_7h_9",
        "outputId": "b860152b-4f76-42e3-ede4-9aa227df8566"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9275 entries, 0 to 9274\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    9275 non-null   object\n",
            " 1   labels  9275 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 145.0+ KB\n",
            "None\n",
            "                                                text  labels\n",
            "0  ## The Advantages of Limiting Car Usage\\n\\nIn ...       1\n",
            "1  The United States is a car-dependent nation, w...       1\n",
            "2  In recent years, there has been a growing move...       1\n",
            "3  In recent years, there has been a growing move...       1\n",
            "4  In the past few decades, the United States has...       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reset index after concatenation\n",
        "combined_dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = combined_dataset['labels'].value_counts()\n",
        "\n",
        "# Print the label counts\n",
        "print(label_counts)\n",
        "\n",
        "# Verify the combined dataset\n",
        "print(combined_dataset.info())\n",
        "print(combined_dataset.head())\n",
        "\n",
        "# Save the combined dataset\n",
        "combined_dataset.to_csv('/content/combined_cleaned_dataset_original.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9st1I_547p96",
        "outputId": "0c9d9835-72e1-41a9-d02d-8c087768168f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels\n",
            "0    6520\n",
            "1    2755\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9275 entries, 0 to 9274\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    9275 non-null   object\n",
            " 1   labels  9275 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 145.0+ KB\n",
            "None\n",
            "                                                text  labels\n",
            "0  ## The Advantages of Limiting Car Usage\\n\\nIn ...       1\n",
            "1  The United States is a car-dependent nation, w...       1\n",
            "2  In recent years, there has been a growing move...       1\n",
            "3  In recent years, there has been a growing move...       1\n",
            "4  In the past few decades, the United States has...       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = combined_dataset['labels'].value_counts()\n",
        "print(\"Before balancing:\")\n",
        "print(label_counts)\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = combined_dataset[combined_dataset.labels == 0]\n",
        "df_minority = combined_dataset[combined_dataset.labels == 1]\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = df_majority.sample(len(df_minority), random_state=42)\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Shuffle the dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Count the occurrences of each label after balancing\n",
        "label_counts_balanced = df_balanced['labels'].value_counts()\n",
        "print(\"After balancing:\")\n",
        "print(label_counts_balanced)\n",
        "\n",
        "# Verify the balanced dataset\n",
        "print(df_balanced.info())\n",
        "print(df_balanced.head())\n",
        "\n",
        "# Save the balanced dataset\n",
        "df_balanced.to_csv('/content/balanced_dataset.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1Pvco5F8Cqr",
        "outputId": "06d3ea40-e029-4ec8-d4a1-1b1d970caed6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before balancing:\n",
            "labels\n",
            "0    6520\n",
            "1    2755\n",
            "Name: count, dtype: int64\n",
            "After balancing:\n",
            "labels\n",
            "0    2755\n",
            "1    2755\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5510 entries, 0 to 5509\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5510 non-null   object\n",
            " 1   labels  5510 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 86.2+ KB\n",
            "None\n",
            "                                                text  labels\n",
            "0  Fire works a little differently than people im...       0\n",
            "1  Were windsock-like flags common back in those ...       0\n",
            "2  It is highly unlikely that any former slaves w...       1\n",
            "3  When Prohibition ended in 1933, the situation ...       1\n",
            "4  Cars. Trucks. motorcycles. All these forms of ...       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the balanced dataset\n",
        "df_balanced = pd.read_csv('/content/balanced_dataset.csv')\n",
        "\n",
        "# Define stop words and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = string.punctuation\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', punctuation))\n",
        "    # Remove stop words\n",
        "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the text column\n",
        "df_balanced['text'] = df_balanced['text'].apply(clean_text)\n",
        "\n",
        "# Verify the cleaned text\n",
        "print(df_balanced.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0hI3pPZ8dku",
        "outputId": "0ca19e16-40b4-4437-cab4-0070554e4400"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  labels\n",
            "0  Fire works little differently people imagineWh...       0\n",
            "1  windsocklike flags common back days Im wonderi...       0\n",
            "2  highly unlikely former slaves would lived long...       1\n",
            "3  Prohibition ended 1933 situation regarding ind...       1\n",
            "4  Cars Trucks motorcycles forms transportation d...       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the text data\n",
        "def tokenize_data(text_list, tokenizer, max_length=128):\n",
        "    return tokenizer(text_list, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df_balanced['text'], df_balanced['labels'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the train and test texts\n",
        "train_encodings = tokenize_data(train_texts.tolist(), tokenizer)\n",
        "test_encodings = tokenize_data(test_texts.tolist(), tokenizer)\n",
        "\n",
        "# Print the shapes of the tokenized data\n",
        "print(train_encodings['input_ids'].shape)\n",
        "print(test_encodings['input_ids'].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j8DZ0wW9Fnt",
        "outputId": "7323bb4a-7b75-4411-be10-62474c1bffc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4408, 128])\n",
            "torch.Size([1102, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZVW6kBp-Cxq",
        "outputId": "0a5f43a6-4287-4831-e979-b1b5794ecc26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxtPvkVT-FXG",
        "outputId": "72179118-bccb-4401-9508-37b1e41f7022"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "\n",
        "# Create torch datasets\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = self.add_labels(encodings, labels)\n",
        "\n",
        "    def add_labels(self, encodings, labels):\n",
        "        encodings['labels'] = labels\n",
        "        return encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = TextDataset(train_encodings, train_labels.tolist())\n",
        "test_dataset = TextDataset(test_encodings, test_labels.tolist())\n",
        "\n",
        "# Load the BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Create the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('/content/bert_model')\n",
        "tokenizer.save_pretrained('/content/bert_tokenizer')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "00a2aee386b546c29f10f21ddb9fb114",
            "a05a314b768a4bf19034c8cbecc7bbb2",
            "6cfbbcdedfc84237af1ead8e060106b8",
            "41be356ccb32476ba305bfb4caa762c9",
            "d6bed21175af4548939192a8bf57ef69",
            "c781724fa02744e4aaf0540fb611b2e4",
            "17dfde63043943018222a088616ddfb1",
            "a8a30cb4d7d84c4cabbd4527ef72ec7b",
            "91d916175e47478c849b56a5b3028661",
            "42dc75824b524ab0991fb64f4b28a8eb",
            "ae398535a42145e4bd205845841acb93"
          ]
        },
        "id": "wnW33rzG9M2W",
        "outputId": "498a6204-6dd9-4055-b0ab-8489b0e874cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00a2aee386b546c29f10f21ddb9fb114"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1653' max='1653' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1653/1653 06:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.691700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.676600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.639200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.585800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.537000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.483700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.479600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.447900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.382000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.284700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.218100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.305200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.287200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.355100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.172000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.328200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.291600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.316700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.228200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.087300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.155800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.144100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.493600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.078800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.161700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.242900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.217700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.394800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.270100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.107800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.251400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.166300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.106900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.111400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.060100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.251700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.223200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.178500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.313300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.245300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.158300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.151600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.144700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.419400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.294600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.141300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.102500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.257500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.150900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.015600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.086300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.206200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.127000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.210400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.146600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.125600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.055800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.089100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.079500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.230600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.091400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.141200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.021800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.056500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.146100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.028600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.034800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.132100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.308500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.080800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.110300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.100800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.049500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.094200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.045200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.114500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.054300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.056800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/bert_tokenizer/tokenizer_config.json',\n",
              " '/content/bert_tokenizer/special_tokens_map.json',\n",
              " '/content/bert_tokenizer/vocab.txt',\n",
              " '/content/bert_tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df_balanced['text'], df_balanced['labels'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split the training set into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Print the shapes of the split datasets\n",
        "print(\"Training set:\", train_texts.shape, train_labels.shape)\n",
        "print(\"Validation set:\", val_texts.shape, val_labels.shape)\n",
        "print(\"Testing set:\", test_texts.shape, test_labels.shape)\n"
      ],
      "metadata": {
        "id": "P5e5KSoB92FS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78633646-7caf-41ed-96c3-fcaa9db1c38f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (3967,) (3967,)\n",
            "Validation set: (441,) (441,)\n",
            "Testing set: (1102,) (1102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the train, validation, and test texts\n",
        "train_encodings = tokenize_data(train_texts.tolist(), tokenizer)\n",
        "val_encodings = tokenize_data(val_texts.tolist(), tokenizer)\n",
        "test_encodings = tokenize_data(test_texts.tolist(), tokenizer)\n"
      ],
      "metadata": {
        "id": "d-0aeNa4B8K0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch',  # Evaluate at the end of each epoch\n",
        "    save_strategy='epoch',  # Save the model at the end of each epoch\n",
        ")\n",
        "\n",
        "# Create the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"Evaluation results:\", eval_results)\n",
        "\n",
        "# Predicting labels for the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(test_labels, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "YczZyNt5C4Wy",
        "outputId": "887cf630-665d-4417-becf-f26c7575cb84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1488' max='1488' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1488/1488 05:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.210700</td>\n",
              "      <td>0.182911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.174069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.177787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 0.10615996271371841, 'eval_runtime': 8.0308, 'eval_samples_per_second': 137.222, 'eval_steps_per_second': 17.184, 'epoch': 3.0}\n",
            "Test Accuracy: 0.9818511796733213\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       565\n",
            "           1       0.98      0.99      0.98       537\n",
            "\n",
            "    accuracy                           0.98      1102\n",
            "   macro avg       0.98      0.98      0.98      1102\n",
            "weighted avg       0.98      0.98      0.98      1102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predicting labels for the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(test_labels, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "r4PlCJuKC7ga",
        "outputId": "f41cddc3-b5a1-475d-d470-8b784231239f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9818511796733213\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       565\n",
            "           1       0.98      0.99      0.98       537\n",
            "\n",
            "    accuracy                           0.98      1102\n",
            "   macro avg       0.98      0.98      0.98      1102\n",
            "weighted avg       0.98      0.98      0.98      1102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "X2AiRSqLIDQO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to predict labels\n",
        "def predict_labels(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        with torch.no_grad():\n",
        "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            predictions.extend(logits.argmax(dim=-1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return true_labels, predictions\n"
      ],
      "metadata": {
        "id": "xLVUERp8IHr0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the specified device\n",
        "model.to(device)\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Predict labels for the test set\n",
        "true_labels, predicted_labels = predict_labels(model, test_dataloader)\n",
        "\n",
        "# Convert label IDs to original labels\n",
        "label_map = {0: \"Label 0\", 1: \"Label 1\"}  # Adjust as per your actual labels\n",
        "\n",
        "true_labels = [label_map[label] for label in true_labels]\n",
        "predicted_labels = [label_map[label] for label in predicted_labels]\n",
        "\n",
        "# Print actual and predicted outputs\n",
        "print(\"Actual labels:\", true_labels)\n",
        "print(\"Predicted labels:\", predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(true_labels, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz6deoflILNV",
        "outputId": "625b710c-aa90-4826-e446-513de24889d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual labels: ['Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0']\n",
            "Predicted labels: ['Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0', 'Label 0', 'Label 0', 'Label 1', 'Label 0', 'Label 1', 'Label 1', 'Label 0', 'Label 0', 'Label 1', 'Label 1', 'Label 1', 'Label 0', 'Label 1', 'Label 0']\n",
            "Test Accuracy: 0.9754990925589837\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Label 0       0.99      0.96      0.98       565\n",
            "     Label 1       0.96      0.99      0.98       537\n",
            "\n",
            "    accuracy                           0.98      1102\n",
            "   macro avg       0.98      0.98      0.98      1102\n",
            "weighted avg       0.98      0.98      0.98      1102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "# Assuming you have already trained and evaluated the model as shown before\n",
        "\n",
        "# Save the model\n",
        "model_path = \"/conyent\"\n",
        "model.save_pretrained(model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Use the loaded model for prediction\n",
        "loaded_model.eval()\n",
        "\n",
        "# Example inference using the loaded model\n",
        "# Assuming `test_dataset` and `test_dataloader` are defined\n",
        "predictions = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    with torch.no_grad():\n",
        "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = loaded_model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        batch_predictions = logits.argmax(dim=-1).cpu().numpy()\n",
        "        predictions.extend(batch_predictions)\n",
        "\n",
        "# Convert label IDs to original labels\n",
        "label_map = {0: \"Label 0\", 1: \"Label 1\"}  # Adjust as per your actual labels\n",
        "predicted_labels = [label_map[label] for label in predictions]\n",
        "\n",
        "# Print predicted outputs\n",
        "print(\"Predicted labels:\", predicted_labels)\n",
        "\n",
        "# Calculate accuracy (if needed)\n",
        "# test_accuracy = accuracy_score(true_labels, predictions)\n",
        "# print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Classification report (if needed)\n",
        "# print(classification_report(true_labels, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "ILUa4QisJO98",
        "outputId": "571337a5-c0b7-4626-d92e-f92632e97681"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /path/to/save/your/model/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f9cafa6d4682>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbatch_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1692\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1071\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1074\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU) is available and set device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move model to the selected device\n",
        "model.to(device)\n",
        "\n",
        "# Example of moving data to device (use this for your DataLoader)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "for batch in data_loader:\n",
        "    inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "    labels = batch['labels'].to(device)\n",
        "    # Further processing and training code here\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "zeaxOjSnHhCF",
        "outputId": "370a1c44-81f0-4c40-c1c9-b668df8cb50d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6958e8e9ca86>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Example of moving data to device (use this for your DataLoader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8a-5opwKavU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}